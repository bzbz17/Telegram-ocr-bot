# ============================================================
# ğŸ¤– bot.py â€” OCR ÙØ§Ø±Ø³ÛŒ / Ø¹Ø±Ø¨ÛŒ / Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ø§ EasyOCR + ocrmypdf + Flask
# ============================================================

import os
import tempfile
import logging
import asyncio
from pathlib import Path
from threading import Thread
import re
import cv2
import numpy as np
from PIL import Image

import pytesseract
import fitz  # PyMuPDF
import easyocr
import ocrmypdf
import arabic_reshaper
from bidi.algorithm import get_display
from flask import Flask
from pdf2image import convert_from_path
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters

# ----------------------------
# ğŸ”§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ
# ----------------------------
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

BOT_TOKEN = os.environ.get("BOT_TOKEN")
POPPLER_PATH = os.environ.get("POPPLER_PATH", "/usr/bin")
LANGS = ["fa", "ar", "en"]

reader = easyocr.Reader(LANGS, gpu=False)

# ----------------------------
# ğŸŒ Flask Ø¨Ø±Ø§ÛŒ UptimeRobot
# ----------------------------
flask_app = Flask(__name__)

@flask_app.route('/')
def home():
    return "âœ… OCR Bot is alive!", 200

def run_flask():
    flask_app.run(host="0.0.0.0", port=10000)

# ----------------------------
# ğŸ§  Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±
# ----------------------------
def preprocess_image(image_path: str) -> np.ndarray:
    """Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ OCR"""
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Ø­Ø°Ù Ù†ÙˆÛŒØ²
    gray = cv2.fastNlMeansDenoising(gray, None, 30, 7, 21)
    # Ø¨Ø§ÛŒÙ†Ø±ÛŒâ€ŒØ³Ø§Ø²ÛŒ (Ø³ÛŒØ§Ù‡ Ùˆ Ø³ÙÛŒØ¯)
    _, th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    # ØªØµØ­ÛŒØ­ Ø²Ø§ÙˆÛŒÙ‡ (deskew)
    coords = np.column_stack(np.where(th > 0))
    angle = cv2.minAreaRect(coords)[-1]
    if angle < -45:
        angle = -(90 + angle)
    else:
        angle = -angle
    (h, w) = th.shape[:2]
    M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)
    rotated = cv2.warpAffine(th, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
    return rotated

# ----------------------------
# ğŸ“„ OCR PDF (Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² PDFÙ‡Ø§ÛŒ Ø§Ø³Ú©Ù†â€ŒØ´Ø¯Ù‡)
# ----------------------------
def extract_text_from_pdf(pdf_path: str) -> str:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ø§Ø² PDF â€” Ù‡Ù… Ø¯ÛŒØ¬ÛŒØªØ§Ù„ Ù‡Ù… Ø§Ø³Ú©Ù†â€ŒØ´Ø¯Ù‡"""
    try:
        text = ""
        # 1. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù† Ù…ØªÙ† Ø¯ÛŒØ¬ÛŒØªØ§Ù„
        with fitz.open(pdf_path) as doc:
            for page in doc:
                t = page.get_text("text")
                if t.strip():
                    text += t + "\n"

        # Ø§Ú¯Ø± Ù…ØªÙ† Ø¯ÛŒØ¬ÛŒØªØ§Ù„ Ù†Ø¯Ø§Ø´Øª â†’ OCR
        if not text.strip():
            logger.info("ğŸ“„ No digital text found â€” performing OCR via ocrmypdf...")
            temp_out = tempfile.mktemp(suffix=".pdf")
            ocrmypdf.ocr(pdf_path, temp_out, language="fas+ara+eng", progress_bar=False)
            images = convert_from_path(temp_out, dpi=300, poppler_path=POPPLER_PATH)
            results = []
            for img in images:
                tmp = tempfile.mktemp(suffix=".png")
                img.save(tmp, "PNG")
                processed = preprocess_image(tmp)
                text_ocr = pytesseract.image_to_string(
                    processed,
                    lang="fas+ara+eng",
                    config="--oem 3 --psm 6 -c preserve_interword_spaces=1"
                )
                results.append(text_ocr)
            text = "\n".join(results)

        # Ø§ØµÙ„Ø§Ø­ Ø®Ø±ÙˆØ¬ÛŒ
        text = text.replace("ÙŠ", "ÛŒ").replace("Ùƒ", "Ú©")
        text = arabic_reshaper.reshape(text)
        text = get_display(text)
        return text.strip()
    except Exception as e:
        logger.error(f"PDF OCR error: {e}")
        return "âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ø§Ø² PDF."

# ----------------------------
# ğŸ–¼ï¸ OCR Image
# ----------------------------
def extract_text_from_image(image_path: str) -> str:
    """OCR Ø§Ø² Ø¹Ú©Ø³ Ø¨Ø§ ØªØ±Ú©ÛŒØ¨ EasyOCR Ùˆ Tesseract"""
    try:
        processed = preprocess_image(image_path)
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² EasyOCR
        results = reader.readtext(processed, detail=0, paragraph=True)
        text_easy = "\n".join(results)

        # ØªØ±Ú©ÛŒØ¨ Ø¨Ø§ pytesseract Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª Ø¨ÛŒØ´ØªØ±
        text_tess = pytesseract.image_to_string(
            processed,
            lang="fas+ara+eng",
            config="--oem 3 --psm 6 -c preserve_interword_spaces=1"
        )
        text = text_easy + "\n" + text_tess
        text = text.replace("ÙŠ", "ÛŒ").replace("Ùƒ", "Ú©")
        text = arabic_reshaper.reshape(text)
        text = get_display(text)
        return text.strip()
    except Exception as e:
        logger.error(f"OCR image error: {e}")
        return "âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±."

# ----------------------------
# ğŸ“¨ Ù…Ø¯ÛŒØ±ÛŒØª ÙØ§ÛŒÙ„ Ø§Ø±Ø³Ø§Ù„ÛŒ Ø§Ø² ØªÙ„Ú¯Ø±Ø§Ù…
# ----------------------------
async def handle_file(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message = update.message
    if not message:
        return

    file_id = None
    file_name = None

    if message.document:
        file_id = message.document.file_id
        file_name = message.document.file_name
    elif message.photo:
        file_id = message.photo[-1].file_id
        file_name = f"{message.photo[-1].file_unique_id}.jpg"
    else:
        await message.reply_text("ğŸ“„ Ù„Ø·ÙØ§Ù‹ ÛŒÚ© ÙØ§ÛŒÙ„ PDF ÛŒØ§ Ø¹Ú©Ø³ Ø¨ÙØ±Ø³ØªÛŒØ¯.")
        return

    tmp_dir = tempfile.mkdtemp()
    local_path = os.path.join(tmp_dir, file_name)

    try:
        telegram_file = await context.bot.get_file(file_id)
        await telegram_file.download_to_drive(custom_path=local_path)
        await message.reply_text("ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ†... Ù„Ø·ÙØ§Ù‹ ØµØ¨Ø± Ú©Ù†ÛŒØ¯.")

        def process():
            if file_name.lower().endswith(".pdf"):
                return extract_text_from_pdf(local_path)
            else:
                return extract_text_from_image(local_path)

        loop = asyncio.get_running_loop()
        text = await loop.run_in_executor(None, process)

        if not text.strip():
            await message.reply_text("âš ï¸ Ù‡ÛŒÚ† Ù…ØªÙ†ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
            return

        # ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ† Ø·ÙˆÙ„Ø§Ù†ÛŒ
        for i in range(0, len(text), 4000):
            await message.reply_text(text[i:i + 4000])

        await message.reply_text("âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")
    except Exception as e:
        logger.exception(e)
        await message.reply_text(f"âŒ Ø®Ø·Ø§: {str(e)}")
    finally:
        for f in Path(tmp_dir).glob("*"):
            f.unlink(missing_ok=True)
        Path(tmp_dir).rmdir()

# ----------------------------
# ğŸš€ Ø¯Ø³ØªÙˆØ± Ø´Ø±ÙˆØ¹
# ----------------------------
async def start_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "ğŸ‘‹ Ø³Ù„Ø§Ù…!\n"
        "Ù…Ù† Ø±Ø¨Ø§Øª OCR Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ù‡Ø³ØªÙ….\n\n"
        "ğŸ“„ ÙØ§ÛŒÙ„ PDF ÛŒØ§ Ø¹Ú©Ø³ Ø¨ÙØ±Ø³Øª ØªØ§ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒØŒ Ø¹Ø±Ø¨ÛŒ ÛŒØ§ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒâ€ŒØ´Ùˆ Ø¨Ø§ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†Ù…."
    )

# ----------------------------
# ğŸ§  Ø§Ø¬Ø±Ø§ÛŒ Ù‡Ù…Ø²Ù…Ø§Ù† Flask Ùˆ Bot
# ----------------------------
def main():
    if not BOT_TOKEN:
        raise RuntimeError("âŒ BOT_TOKEN ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡!")

    # Flask Ø¨Ø±Ø§ÛŒ UptimeRobot
    Thread(target=run_flask).start()

    # Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start_cmd))
    app.add_handler(MessageHandler(filters.Document.ALL | filters.PHOTO, handle_file))

    logger.info("ğŸ¤– OCR Bot started with Flask keep-alive ...")
    app.run_polling()

if __name__ == "__main__":
    main()
