# =============================================================
# ğŸ¤– bot.py â€” OCR Ù‡ÙˆØ´Ù…Ù†Ø¯ ÙØ§Ø±Ø³ÛŒ/Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ø§ ØªØ´Ø®ÛŒØµ Ø¯Ø³Øªâ€ŒÙ†ÙˆÛŒØ³ ÛŒØ§ ØªØ§ÛŒÙ¾â€ŒØ´Ø¯Ù‡
# =============================================================

import os
import tempfile
import logging
import re
import asyncio
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from typing import Optional

import pytesseract
import cv2
import numpy as np
from PIL import Image, ImageEnhance, ImageOps
from pdf2image import convert_from_path
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters

# ----------------------------
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ
# ----------------------------
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

BOT_TOKEN = os.environ.get("BOT_TOKEN")
POPPLER_PATH = os.environ.get("POPPLER_PATH", "/usr/bin")

MAX_WORKERS = int(os.environ.get("OCR_MAX_WORKERS", "6"))
executor = ThreadPoolExecutor(max_workers=MAX_WORKERS)

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª OCR Ù¾Ø§ÛŒÙ‡ (Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ + ÙØ§ØµÙ„Ù‡ ØµØ­ÛŒØ­)
OCR_CONFIG = "--oem 3 --psm 6 -c preserve_interword_spaces=1 --tessdata-dir /usr/share/tesseract-ocr/4.00/tessdata"


# ----------------------------
# ğŸ§  ØªØ§Ø¨Ø¹ ØªØ´Ø®ÛŒØµ Ø¯Ø³Øªâ€ŒÙ†ÙˆÛŒØ³ ÛŒØ§ ØªØ§ÛŒÙ¾â€ŒØ´Ø¯Ù‡
# ----------------------------
def detect_handwritten(image: np.ndarray) -> bool:
    """
    Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ø¢ÛŒØ§ ØªØµÙˆÛŒØ± Ø¨ÛŒØ´ØªØ± Ø¯Ø³Øªâ€ŒÙ†ÙˆÛŒØ³ Ø§Ø³Øª ÛŒØ§ Ú†Ø§Ù¾ÛŒ.
    Ù…Ø¨Ù†Ø§: ØªØ±Ø§Ú©Ù… Ù„Ø¨Ù‡â€ŒÙ‡Ø§ Ùˆ Ø´Ú©Ù„ Ø­Ø±ÙˆÙ.
    """
    try:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        density = np.sum(edges > 0) / edges.size

        # Ø§Ú¯Ø± ØªØ±Ø§Ú©Ù… Ø®Ø·ÙˆØ· Ø¨Ø§Ù„Ø§ Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø­ØªÙ…Ø§Ù„ Ø¯Ø³Øªâ€ŒÙ†ÙˆÛŒØ³ Ø¨ÙˆØ¯Ù† Ø¨ÛŒØ´ØªØ± Ø§Ø³Øª.
        return density > 0.05
    except Exception as e:
        logger.error(f"Handwriting detection error: {e}")
        return False


# ----------------------------
# ğŸ§© Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±
# ----------------------------
def preprocess_image(img: Image.Image, handwritten: bool = False) -> Image.Image:
    """Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªØµÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ OCRØŒ Ø¨Ø³ØªÙ‡ Ø¨Ù‡ Ù†ÙˆØ¹ Ù…ØªÙ†"""
    img = img.convert("L")
    if img.width < 1000:
        scale = 1000 / img.width
        img = img.resize((int(img.width * scale), int(img.height * scale)), Image.Resampling.LANCZOS)
    img = ImageOps.autocontrast(img, cutoff=2)

    if handwritten:
        # Ø¨Ø±Ø§ÛŒ Ù…ØªÙ† Ø¯Ø³Øªâ€ŒÙ†ÙˆÛŒØ³: Ø§ÙØ²Ø§ÛŒØ´ Ø´Ø¯Øª Ùˆ Ø­Ø°Ù Ø³Ø§ÛŒÙ‡
        img = ImageEnhance.Contrast(img).enhance(2.0)
        img = ImageEnhance.Sharpness(img).enhance(1.8)
    else:
        # Ø¨Ø±Ø§ÛŒ Ù…ØªÙ† ØªØ§ÛŒÙ¾â€ŒØ´Ø¯Ù‡: ØµØ§Ù Ùˆ Ø´ÙØ§Ùâ€ŒØªØ±
        img = ImageEnhance.Contrast(img).enhance(1.4)
        img = ImageEnhance.Sharpness(img).enhance(1.2)

    img = img.point(lambda x: 255 if x > 160 else 0, mode="1")
    return img


# ----------------------------
# ğŸŒ ØªØ´Ø®ÛŒØµ Ø²Ø¨Ø§Ù†
# ----------------------------
def detect_language(image: Image.Image) -> str:
    """ØªØ´Ø®ÛŒØµ Ø³Ø±ÛŒØ¹ Ø²Ø¨Ø§Ù† ØºØ§Ù„Ø¨"""
    try:
        txt = pytesseract.image_to_string(image, lang="fas+eng", config="--psm 6")
        farsi = len(re.findall(r'[\u0600-\u06FF]', txt))
        english = len(re.findall(r'[A-Za-z]', txt))
        return "fas_fast+eng" if farsi > english else "eng"
    except Exception:
        return "fas_fast+eng"


# ----------------------------
# ğŸ” OCR Ø±ÙˆÛŒ ØªØµÙˆÛŒØ±
# ----------------------------
def ocr_image_to_text(img: Image.Image, lang: str, handwritten: bool) -> str:
    """Ø§Ø¬Ø±Ø§ÛŒ OCR Ø¨Ø§ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ ÙØ§ØµÙ„Ù‡ Ø¨ÛŒÙ† Ú©Ù„Ù…Ø§Øª"""
    processed = preprocess_image(img, handwritten)
    data = pytesseract.image_to_data(
        processed, lang=lang, config=OCR_CONFIG, output_type=pytesseract.Output.DICT
    )

    lines = {}
    for i, text in enumerate(data["text"]):
        if not text.strip():
            continue
        y = data["top"][i]
        line_key = round(y / 40)
        lines.setdefault(line_key, []).append((data["left"][i], text))

    full_text = []
    for _, words in sorted(lines.items()):
        words = sorted(words, key=lambda x: x[0], reverse=True)
        line = " ".join(w for _, w in words)
        full_text.append(line)

    text = "\n".join(full_text).strip()
    text = text.replace("ÙŠ", "ÛŒ").replace("Ùƒ", "Ú©")
    return text


# ----------------------------
# ğŸ“„ OCR PDF Ú†Ù†Ø¯ ØµÙØ­Ù‡â€ŒØ§ÛŒ
# ----------------------------
def ocr_pdf_to_text(pdf_path: str, poppler_path: Optional[str] = None) -> str:
    """ØªØ¨Ø¯ÛŒÙ„ PDF Ø¨Ù‡ Ù…ØªÙ† OCR Ø¨Ø§ ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ù…ØªÙ† (Ø¯Ø³Øªâ€ŒÙ†ÙˆÛŒØ³/ØªØ§ÛŒÙ¾â€ŒØ´Ø¯Ù‡)"""
    images = convert_from_path(pdf_path, dpi=200, poppler_path=poppler_path)
    results = []

    for img in images:
        np_img = np.array(img)
        handwritten = detect_handwritten(np_img)
        lang = detect_language(img)
        text = ocr_image_to_text(img, lang, handwritten)
        results.append(text)

    return "\n\n".join(results).strip()


# ----------------------------
# ğŸ“¨ Ø¯Ø±ÛŒØ§ÙØª ÙØ§ÛŒÙ„ Ø§Ø² ØªÙ„Ú¯Ø±Ø§Ù…
# ----------------------------
async def handle_file(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = update.message
    if not msg:
        return

    if msg.document:
        file_id = msg.document.file_id
        file_name = msg.document.file_name or "file.pdf"
    elif msg.photo:
        file_id = msg.photo[-1].file_id
        file_name = f"{msg.photo[-1].file_unique_id}.jpg"
    else:
        await msg.reply_text("ğŸ“„ Ù„Ø·ÙØ§Ù‹ ÛŒÚ© ÙØ§ÛŒÙ„ PDF ÛŒØ§ Ø¹Ú©Ø³ Ø¨ÙØ±Ø³Øª.")
        return

    tmp_dir = tempfile.mkdtemp()
    local_path = os.path.join(tmp_dir, file_name)

    try:
        file = await context.bot.get_file(file_id)
        await file.download_to_drive(custom_path=local_path)
        await msg.reply_text("â³ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡ÙˆØ´Ù…Ù†Ø¯ ØªØµÙˆÛŒØ± Ùˆ ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ù…ØªÙ† ...")

        def process():
            if file_name.lower().endswith(".pdf"):
                return ocr_pdf_to_text(local_path, poppler_path=POPPLER_PATH)
            else:
                img = Image.open(local_path)
                np_img = np.array(img)
                handwritten = detect_handwritten(np_img)
                lang = detect_language(img)
                return ocr_image_to_text(img, lang, handwritten)

        loop = asyncio.get_running_loop()
        text = await loop.run_in_executor(executor, process)

        if not text.strip():
            await msg.reply_text("âš ï¸ Ù…ØªÙ†ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
            return

        for i in range(0, len(text), 4000):
            await msg.reply_text(text[i:i + 4000])

        await msg.reply_text("âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")
    except Exception as e:
        logger.exception(e)
        await msg.reply_text(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´: {str(e)}")
    finally:
        for f in Path(tmp_dir).glob("*"):
            f.unlink(missing_ok=True)
        Path(tmp_dir).rmdir()


# ----------------------------
# ğŸš€ ÙØ±Ù…Ø§Ù† Ø´Ø±ÙˆØ¹
# ----------------------------
async def start_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "ğŸ‘‹ Ø³Ù„Ø§Ù…!\n"
        "Ù…Ù† Ø±Ø¨Ø§Øª OCR Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù‡Ø³ØªÙ… ğŸ“‘\n"
        "ÙØ§ÛŒÙ„ PDF ÛŒØ§ Ø¹Ú©Ø³ Ø¨ÙØ±Ø³Øª ØªØ§ ØªØ´Ø®ÛŒØµ Ø¨Ø¯Ù… ØªØ§ÛŒÙ¾â€ŒØ´Ø¯Ù‡â€ŒØ³Øª ÛŒØ§ Ø¯Ø³Øªâ€ŒÙ†ÙˆÛŒØ³ Ùˆ Ù…ØªÙ†Ø´ Ø±Ùˆ Ø¨Ø§ Ø¯Ù‚Øª Ø¨Ø§Ù„Ø§ Ø¨Ø±Ø§Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†Ù… ğŸ’ª"
    )


# ----------------------------
# ğŸ§  Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ
# ----------------------------
def main():
    if not BOT_TOKEN:
        raise RuntimeError("âŒ BOT_TOKEN ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡!")

    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start_cmd))
    app.add_handler(MessageHandler(filters.Document.ALL | filters.PHOTO, handle_file))

    logger.info("ğŸ¤– Smart OCR Bot started successfully ...")
    app.run_polling()


if __name__ == "__main__":
    main()
